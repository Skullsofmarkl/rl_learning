"""
Настройки среды highway-env для обучения RL агентов автономному вождению.

Highway-env - это симулятор автономного вождения на шоссе, который предоставляет:
- Реалистичную среду с движущимися автомобилями
- Дискретные действия для управления транспортным средством
- Наблюдения в виде кинематических данных окружающих автомобилей
- Систему наград для поощрения безопасного и эффективного вождения

Содержит функции для создания и конфигурации среды:
- create_highway_env() - основная среда для обучения агентов
- create_video_env() - среда для записи видео демонстраций

Особенности среды:
- 3 полосы движения с двусторонним движением
- 25 автомобилей на дороге для создания реалистичного трафика
- 4 дискретных действия: влево, прямо, вправо, тормоз
- Наблюдения включают позицию, скорость и присутствие других автомобилей
- Система наград поощряет безопасность, скорость и движение по правой полосе
"""

import gymnasium as gym
import highway_env


def create_highway_env():
    """
    Создает и настраивает среду highway-env для обучения RL агентов.

    Настройки оптимизированы для эффективного обучения:
    - duration: 200 - длинные эпизоды для взаимодействия с трафиком
    - vehicles_count: 25 - больше машин для создания сложности
    - initial_spacing: 1.5 - плотнее трафик для реалистичности
    - collision_reward: -15 - сильное наказание за аварии
    - simulation_frequency: 15 - частота симуляции физики
    - policy_frequency: 15 - частота принятия решений агентом
    - action_type: DiscreteMetaAction - дискретные действия для highway-fast-v0

    Returns:
        gym.Env: настроенная среда highway-env
    """
    # Создаем среду highway-fast-v0 с RGB рендерингом
    env = gym.make("highway-fast-v0", render_mode="rgb_array")

    # Настройка параметров среды для оптимального обучения
    if hasattr(env.unwrapped, "configure"):
        env.unwrapped.configure({
            # Настройки наблюдений (observation space)
            "observation": {
                "type": "Kinematics",           # Тип наблюдений - кинематические данные
                "vehicles_count": 5,            # Количество видимых автомобилей
                "absolute": False,              # Относительные координаты (относительно агента)
                "order": "sorted",              # Сортировка автомобилей по расстоянию
                "features": ["presence", "x", "y", "vx", "vy"],  # Признаки: наличие, позиция, скорость
                "features_range": {             # Диапазоны нормализации признаков
                    "x": [-100, 100],          # Позиция по X (метры)
                    "y": [-100, 100],          # Позиция по Y (метры)
                    "vx": [-20, 20],           # Скорость по X (м/с)
                    "vy": [-20, 20]            # Скорость по Y (м/с)
                }
            },
            # Настройки действий (action space)
            "action": {
                "type": "DiscreteMetaAction"    # Дискретные действия: влево, прямо, вправо, тормоз
            },
            # Настройки дороги
            "lanes_count": 3,                   # Количество полос движения
            "vehicles_count": 25,               # Общее количество автомобилей на дороге
            "duration": 200,                    # Длительность эпизода (шаги)
            "initial_spacing": 1.5,             # Начальное расстояние между автомобилями
            # Система наград
            "collision_reward": -15,            # Награда за столкновение (сильное наказание)
            "right_lane_reward": 0.6,           # Награда за движение по правой полосе
            "high_speed_reward": 0.4,           # Награда за высокую скорость
            "reward_speed_range": [20, 60],     # Диапазон скоростей для награды (км/ч)
            "normalize_reward": True,           # Нормализация наград
            "offroad_terminal": True,           # Завершение эпизода при съезде с дороги
            # Настройки симуляции
            "simulation_frequency": 15,         # Частота обновления физики (Гц)
            "policy_frequency": 15              # Частота принятия решений агентом (Гц)
        })

    return env


def create_video_env():
    """
    Создает среду highway-env специально для записи видео демонстраций.

    Отличается от основной среды обучения:
    - duration: 300 - более длинные эпизоды для лучшего демо
    - Остальные параметры идентичны для консистентности
    - Оптимизирована для качественного рендеринга и записи

    Returns:
        gym.Env: настроенная среда highway-env для видео
    """
    # Создаем среду highway-fast-v0 с RGB рендерингом для видео
    env = gym.make("highway-fast-v0", render_mode="rgb_array")

    # Настройка параметров среды для записи видео
    if hasattr(env.unwrapped, "configure"):
        env.unwrapped.configure({
            # Настройки наблюдений (аналогично основной среде)
            "observation": {
                "type": "Kinematics",           # Тип наблюдений - кинематические данные
                "vehicles_count": 5,            # Количество видимых автомобилей
                "absolute": False,              # Относительные координаты (относительно агента)
                "order": "sorted",              # Сортировка автомобилей по расстоянию
                "features": ["presence", "x", "y", "vx", "vy"],  # Признаки: наличие, позиция, скорость
                "features_range": {             # Диапазоны нормализации признаков
                    "x": [-100, 100],          # Позиция по X (метры)
                    "y": [-100, 100],          # Позиция по Y (метры)
                    "vx": [-20, 20],           # Скорость по X (м/с)
                    "vy": [-20, 20]            # Скорость по Y (м/с)
                }
            },
            # Настройки действий (аналогично основной среде)
            "action": {
                "type": "DiscreteMetaAction"    # Дискретные действия: влево, прямо, вправо, тормоз
            },
            # Настройки дороги (аналогично основной среде)
            "lanes_count": 3,                   # Количество полос движения
            "vehicles_count": 25,               # Общее количество автомобилей на дороге
            "duration": 300,                    # Длительность эпизода (длиннее для демо)
            "initial_spacing": 1.5,             # Начальное расстояние между автомобилями
            # Система наград (аналогично основной среде)
            "collision_reward": -15,            # Награда за столкновение (сильное наказание)
            "right_lane_reward": 0.6,           # Награда за движение по правой полосе
            "high_speed_reward": 0.4,           # Награда за высокую скорость
            "reward_speed_range": [20, 60],     # Диапазон скоростей для награды (км/ч)
            "normalize_reward": True,           # Нормализация наград
            "offroad_terminal": True,           # Завершение эпизода при съезде с дороги
            # Настройки симуляции (аналогично основной среде)
            "simulation_frequency": 15,         # Частота обновления физики (Гц)
            "policy_frequency": 15              # Частота принятия решений агентом (Гц)
        })

    return env
